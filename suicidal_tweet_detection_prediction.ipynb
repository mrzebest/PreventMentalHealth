{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Setup backup path"
      ],
      "metadata": {
        "id": "w6uiIr6bGAwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "NuEzFgDUFpRj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_folder_path = \"/gdrive/MyDrive/ESTIAM/E5/AI-ML-Model-Design/\"\n",
        "backup_folder_path = f\"{base_folder_path}/Exam-Model-Backup\"\n",
        "model_file_path = f\"{backup_folder_path}/suicidal_tweet_detector.keras\"\n",
        "tokenizer_file_path = f\"{backup_folder_path}/tokenizer.json\""
      ],
      "metadata": {
        "id": "TNKhuYKzEPpj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVdmZX9cFusm",
        "outputId": "b8f46fa6-65cf-46a4-e263-c7712f570d26"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls {backup_folder_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWOWMUwPGr-w",
        "outputId": "577dfe71-4938-40fd-aa63-bfc466192f58"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "suicidal_tweet_detector.keras  tokenizer.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(tokenizer_file_path, \"r\") as tokenizer_file:\n",
        "    tokenizer_json = json.load(tokenizer_file)\n",
        "\n",
        "tokenizer: Tokenizer = tokenizer_from_json(tokenizer_json)"
      ],
      "metadata": {
        "id": "M30cgw02MZhi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_suicidal_tweet_detector = tf.keras.models.load_model(model_file_path)"
      ],
      "metadata": {
        "id": "CocMcGNLM-Te"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PADDED_SEQ_SIZE = 120"
      ],
      "metadata": {
        "id": "WfbZB1pMMu20"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [\"Not Suicide post\", \"Potential Suicide post\"]"
      ],
      "metadata": {
        "id": "PmJX7QaONedI"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = [\n",
        "    \"I'm so tired of this world, I'm gonna sleep forever\",\n",
        "    \"I'm going to school\",\n",
        "    \"Life is so difficult, I wanna end it here\",\n",
        "    \"I'm going to kill myself\",\n",
        "    \"I want to make a suicide\",\n",
        "]\n",
        "samples_seq = tokenizer.texts_to_sequences(samples)\n",
        "padded_samples_seq = pad_sequences(samples_seq, maxlen=PADDED_SEQ_SIZE)\n",
        "\n",
        "logits = loaded_suicidal_tweet_detector.predict(padded_samples_seq)\n",
        "\n",
        "preds = np.argmax(logits, axis=1)\n",
        "\n",
        "for input, output in zip(samples, preds):\n",
        "    print(\"Input Text:\", input)\n",
        "    print(\"Predicted Label:\", output)\n",
        "    print(\"Predicted Class:\", labels[output])\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxvKFhAKM7xz",
        "outputId": "e8ae7049-f9c3-4f18-e3b7-549680b5c9e0"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Input Text: I'm so tired of this world, I'm gonna sleep forever\n",
            "Predicted Label: 1\n",
            "Predicted Class: Potential Suicide post\n",
            "\n",
            "Input Text: I'm going to school\n",
            "Predicted Label: 0\n",
            "Predicted Class: Not Suicide post\n",
            "\n",
            "Input Text: Life is so difficult, I wanna end it here\n",
            "Predicted Label: 1\n",
            "Predicted Class: Potential Suicide post\n",
            "\n",
            "Input Text: I'm going to kill myself\n",
            "Predicted Label: 0\n",
            "Predicted Class: Not Suicide post\n",
            "\n",
            "Input Text: I want to make a suicide\n",
            "Predicted Label: 0\n",
            "Predicted Class: Not Suicide post\n",
            "\n"
          ]
        }
      ]
    }
  ]
}